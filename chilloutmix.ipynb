{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fulltrick/-/blob/main/chilloutmix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEhAxoUjWOkT",
        "outputId": "f367d973-8b36-458f-9a67-377cd92427e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎭 ChilloutMix Stable Diffusion WebUI セットアップ開始\n",
            "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
            "🔄 環境をクリーンアップ中...\n",
            "✅ 既存のStable Diffusion WebUIディレクトリを削除\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Driveマウント完了\n",
            "\n",
            "📝 ChilloutMixについて:\n",
            "• リアルな人物画像生成に特化したモデル\n",
            "• アジア系女性の画像生成で高い品質を発揮\n",
            "• 写実的なポートレート生成が得意\n",
            "• ファイルサイズ: 約4.27GB\n",
            "\n",
            "📦 必要なパッケージをインストール中...\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "⬇️ Stable Diffusion Web UIをクローン中...\n",
            "/content\n",
            "🔥 PyTorch + CUDA 12.1をインストール中...\n",
            "/content/stable-diffusion-webui\n",
            "🔌 拡張機能をインストール中...\n",
            "/content/stable-diffusion-webui/extensions\n",
            "✅ 拡張機能のインストール完了\n",
            "🎭 ChilloutMixモデルをダウンロード中...\n",
            "⬇️ ChilloutMix-Ni (4.27GB) をダウンロード中...\n",
            "✅ ChilloutMix-Ni ダウンロード完了 (3.97 GB)\n",
            "\n",
            "🎨 VAEモデルをダウンロード中...\n",
            "⬇️ vae-ft-mse-840000-ema-pruned.safetensors をダウンロード中...\n",
            "✅ vae-ft-mse-840000-ema-pruned.safetensors ダウンロード完了\n",
            "\n",
            "🎮 ControlNet モデルをダウンロード中...\n",
            "⬇️ control_v11p_sd15_openpose.pth をダウンロード中...\n",
            "✅ control_v11p_sd15_openpose.pth ダウンロード完了\n",
            "⬇️ control_v11f1p_sd15_depth.pth をダウンロード中...\n",
            "✅ control_v11f1p_sd15_depth.pth ダウンロード完了\n",
            "⬇️ control_v11p_sd15_canny.pth をダウンロード中...\n",
            "✅ control_v11p_sd15_canny.pth ダウンロード完了\n",
            "\n",
            "📚 追加ライブラリをインストール中...\n",
            "🔧 xFormersの互換性問題を修正中...\n",
            "Found existing installation: xformers 0.0.20\n",
            "Uninstalling xformers-0.0.20:\n",
            "  Successfully uninstalled xformers-0.0.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.21 requires protobuf<5,>=4.25.3, but you have protobuf 3.20.3 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.24.1 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ xFormers修正完了\n",
            "⚙️ ChilloutMix用設定ファイルを作成中...\n",
            "✅ 設定ファイル作成完了\n",
            "\n",
            "============================================================\n",
            "🎭 ChilloutMix セットアップ完了サマリー:\n",
            "============================================================\n",
            "📁 インストールされたモデル:\n",
            "   ✅ chilloutmix_NiPrunedFp32Fix.safetensors (3.97 GB)\n",
            "\n",
            "🔌 インストールされた拡張機能:\n",
            "   ✅ a1111-sd-webui-tagcomplete\n",
            "   ✅ multidiffusion-upscaler-for-automatic1111\n",
            "   ✅ sd-webui-controlnet\n",
            "   ✅ CodeFormer\n",
            "\n",
            "🎯 ChilloutMix 推奨設定:\n",
            "   📸 モデル: ChilloutMix-Ni\n",
            "   📐 解像度: 512x768 または 512x512\n",
            "   🎛️ CFG Scale: 7-12\n",
            "   🔄 Steps: 20-30\n",
            "   🎲 Sampler: DPM++ 2M Karras または Euler a\n",
            "   🎨 CLIP Skip: 2\n",
            "\n",
            "✨ ChilloutMix 特徴:\n",
            "   • リアルな人物画像生成に特化\n",
            "   • アジア系女性のポートレートで高品質\n",
            "   • 写実的な肌質・髪質表現\n",
            "   • スタジオ撮影風の画像生成\n",
            "\n",
            "💡 推奨プロンプト例:\n",
            "   • \"1girl, portrait, realistic, beautiful detailed eyes\"\n",
            "   • \"professional photography, studio lighting, asian girl\"\n",
            "   • \"masterpiece, best quality, photorealistic, upper body\"\n",
            "\n",
            "⚠️ Google Colab使用時の注意事項:\n",
            "   • メモリ不足エラーが出た場合は解像度を512x512に下げる\n",
            "   • 長時間使用すると接続が切れる場合がある\n",
            "   • 高品質画像は時間がかかる場合がある\n",
            "\n",
            "🔧 エラー対策済み:\n",
            "   • xFormersバージョン不整合を修正\n",
            "   • GFPGAN依存関係エラーを解決\n",
            "   • メモリ効率を改善（--lowvram使用）\n",
            "   • CUDA最適化設定を追加\n",
            "\n",
            "============================================================\n",
            "🚀 ChilloutMix Web UIを起動中...\n",
            "⏳ 初回起動には数分かかる場合があります...\n",
            "\n",
            "📱 起動完了後、共有URLが表示されます\n",
            "/content/stable-diffusion-webui\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Version: v1.10.1\n",
            "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
            "Cloning assets into /content/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 132.70 KiB | 2.29 MiB/s, done.\n",
            "Cloning Stable Diffusion into /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...\n",
            "remote: Enumerating objects: 586, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 586 (delta 2), reused 0 (delta 0), pack-reused 579 (from 5)\u001b[K\n",
            "Receiving objects: 100% (586/586), 73.45 MiB | 29.79 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n",
            "Cloning Stable Diffusion XL into /content/stable-diffusion-webui/repositories/generative-models...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/generative-models'...\n",
            "remote: Enumerating objects: 1108, done.\u001b[K\n",
            "remote: Counting objects: 100% (519/519), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 1108 (delta 417), reused 365 (delta 365), pack-reused 589 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1108/1108), 86.65 MiB | 56.62 MiB/s, done.\n",
            "Resolving deltas: 100% (578/578), done.\n",
            "Cloning K-diffusion into /content/stable-diffusion-webui/repositories/k-diffusion...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/k-diffusion'...\n",
            "remote: Enumerating objects: 1350, done.\u001b[K\n",
            "remote: Counting objects: 100% (1350/1350), done.\u001b[K\n",
            "remote: Compressing objects: 100% (444/444), done.\u001b[K\n",
            "remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1350/1350), 233.36 KiB | 2.95 MiB/s, done.\n",
            "Resolving deltas: 100% (951/951), done.\n",
            "Cloning BLIP into /content/stable-diffusion-webui/repositories/BLIP...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.04 MiB | 30.27 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Installing requirements\n",
            "ControlNet init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "Launching Web UI with arguments: --share --skip-torch-cuda-test --disable-console-progressbars --opt-sdp-attention --enable-insecure-extension-access --lora-dir /content/stable-diffusion-webui/models/Lora --no-half --precision full --medvram --no-half-vae --api '--cors-allow-origins=*'\n",
            "2025-08-12 06:14:48.727151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754979288.748474   10912 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754979288.754873   10912 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754979288.771223   10912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754979288.771249   10912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754979288.771253   10912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754979288.771255   10912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.5.1+cu121)\n",
            "    Python  3.11.3 (you have 3.11.13)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/swiglu_op.py:106: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/swiglu_op.py:127: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_bwd\n",
            "No module 'xformers'. Proceeding without it.\n",
            "*** Error loading script: crop_align_face.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/scripts.py\", line 515, in load_scripts\n",
            "        script_module = script_loading.load_module(scriptfile.path)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/script_loading.py\", line 13, in load_module\n",
            "        module_spec.loader.exec_module(module)\n",
            "      File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "      File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "      File \"/content/stable-diffusion-webui/extensions/CodeFormer/scripts/crop_align_face.py\", line 24, in <module>\n",
            "        from basicsr.utils.download_util import load_file_from_url\n",
            "      File \"/content/stable-diffusion-webui/extensions/CodeFormer/basicsr/__init__.py\", line 5, in <module>\n",
            "        from .losses import *\n",
            "      File \"/content/stable-diffusion-webui/extensions/CodeFormer/basicsr/losses/__init__.py\", line 5, in <module>\n",
            "        from .losses import (CharbonnierLoss, GANLoss, L1Loss, MSELoss, PerceptualLoss, WeightedTVLoss, g_path_regularize,\n",
            "      File \"/content/stable-diffusion-webui/extensions/CodeFormer/basicsr/losses/losses.py\", line 2, in <module>\n",
            "        import lpips\n",
            "    ModuleNotFoundError: No module named 'lpips'\n",
            "\n",
            "---\n",
            "Tag Autocomplete: Creating frequency database\n",
            "Tag Autocomplete: Database successfully created\n",
            "Tag Autocomplete: Could not locate model-keyword extension, Lora trigger word completion will be limited to those added through the extra networks menu.\n",
            "ControlNet preprocessor location: /content/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads\n",
            "2025-08-12 06:14:54,219 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet v1.1.455\n",
            "2025-08-12 06:14:54,730 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "Calculating sha256 for /content/stable-diffusion-webui/models/Stable-diffusion/chilloutmix_NiPrunedFp32Fix.safetensors: Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://12e5bc234b717bc190.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 30.1s (prepare environment: 14.9s, import torch: 5.6s, import gradio: 0.9s, setup paths: 3.9s, initialize shared: 0.2s, other imports: 0.4s, load scripts: 2.0s, create ui: 0.9s, gradio launch: 0.5s, add APIs: 0.5s).\n",
            "fc2511737a54c5e80b89ab03e0ab4b98d051ab187f92860f3cd664dc9d08b271\n",
            "Loading weights [fc2511737a] from /content/stable-diffusion-webui/models/Stable-diffusion/chilloutmix_NiPrunedFp32Fix.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Applying attention optimization: sdp... done.\n",
            "Model loaded in 15.4s (calculate hash: 13.7s, create model: 0.5s, apply weights to model: 0.9s, calculate empty prompt: 0.3s).\n",
            "/content/stable-diffusion-webui/modules/safe.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return unsafe_torch_load(filename, *args, **kwargs)\n",
            "100% 20/20 [00:07<00:00,  2.64it/s]\n",
            "2025-08-12 06:17:14,972 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "*** Error running process: /content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/scripts.py\", line 832, in process\n",
            "        script.process(p, *script_args)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1228, in process\n",
            "        self.controlnet_hack(p)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1213, in controlnet_hack\n",
            "        self.controlnet_main_entry(p)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 919, in controlnet_main_entry\n",
            "        model_net, control_model_type = Script.load_control_model(p, unet, unit.model)\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 436, in load_control_model\n",
            "        control_model = Script.build_control_model(p, unet, model)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 446, in build_control_model\n",
            "        raise RuntimeError(\"You have not selected any ControlNet Model.\")\n",
            "    RuntimeError: You have not selected any ControlNet Model.\n",
            "\n",
            "---\n",
            "100% 20/20 [00:07<00:00,  2.66it/s]\n",
            "2025-08-12 06:17:36,191 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:17:36,684 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:17:36,684 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:17:38,857 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 2.6698639392852783\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:17:42,800 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 64]).\n",
            "100% 20/20 [00:14<00:00,  1.35it/s]\n",
            "2025-08-12 06:18:27,308 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:18:27,800 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:18:27,801 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:18:29,987 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 2.6830921173095703\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:18:32,978 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 54]).\n",
            "100% 20/20 [00:11<00:00,  1.69it/s]\n",
            "2025-08-12 06:19:10,879 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:19:11,373 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:19:11,373 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:19:13,599 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 2.723912000656128\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:19:17,480 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 54]).\n",
            "100% 20/20 [00:12<00:00,  1.54it/s]\n",
            "2025-08-12 06:19:50,322 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:19:50,861 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:19:50,861 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:19:53,042 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 2.7235450744628906\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:19:56,055 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 86, 54]).\n",
            "100% 20/20 [00:16<00:00,  1.24it/s]\n",
            "2025-08-12 06:20:33,583 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:20:34,070 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:20:34,070 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:20:39,045 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.465754270553589\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:20:41,981 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 86, 54]).\n",
            "100% 20/20 [00:15<00:00,  1.25it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:20:57,043 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 172, 108]).\n",
            "100% 20/20 [02:04<00:00,  6.24s/it]\n",
            "2025-08-12 06:27:04,573 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:27:05,107 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:27:05,107 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:27:10,103 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.533219814300537\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:27:13,020 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 86, 54]).\n",
            "100% 20/20 [00:14<00:00,  1.37it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:27:26,829 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 172, 108]).\n",
            "100% 20/20 [02:04<00:00,  6.24s/it]\n",
            "2025-08-12 06:30:46,756 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:30:47,244 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:30:47,244 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:30:49,812 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 3.05996036529541\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:30:52,716 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 63, 64]).\n",
            "100% 20/20 [00:12<00:00,  1.57it/s]\n",
            "2025-08-12 06:31:23,380 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:31:23,869 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:31:23,869 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:31:28,516 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.14039158821106\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:31:32,508 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 63, 64]).\n",
            "100% 20/20 [00:14<00:00,  1.41it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:31:45,060 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 126, 128]).\n",
            "100% 20/20 [01:48<00:00,  5.41s/it]\n",
            "2025-08-12 06:36:11,447 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "*** Error running process: /content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/scripts.py\", line 832, in process\n",
            "        script.process(p, *script_args)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1228, in process\n",
            "        self.controlnet_hack(p)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1213, in controlnet_hack\n",
            "        self.controlnet_main_entry(p)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 890, in controlnet_main_entry\n",
            "        Preprocessor.unload_unused(active_processors={\n",
            "                                                     ^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 893, in <setcomp>\n",
            "        for p in unit.get_actual_preprocessors()\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/internal_controlnet/args.py\", line 274, in get_actual_preprocessors\n",
            "        p = p.get_preprocessor_by_model(self.model)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/preprocessor/ip_adapter_auto.py\", line 16, in get_preprocessor_by_model\n",
            "        module: str = IPAdapterPreset.match_model(model).module\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/ipadapter/presets.py\", line 20, in match_model\n",
            "        model_name in _preset_by_model\n",
            "    AssertionError: None not found in ipadapter presets. Please try manually pick preprocessor.\n",
            "\n",
            "---\n",
            "100% 20/20 [00:04<00:00,  4.23it/s]\n",
            "Downloading: \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\" to /content/stable-diffusion-webui/models/GFPGAN/GFPGANv1.4.pth\n",
            "\n",
            "100% 332M/332M [00:01<00:00, 265MB/s]\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/stable-diffusion-webui/models/GFPGAN/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 254MB/s] \n",
            "/content/stable-diffusion-webui/modules/safe.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return unsafe_torch_load(filename, *args, **kwargs)\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\" to /content/stable-diffusion-webui/models/GFPGAN/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:00<00:00, 245MB/s]\n",
            "2025-08-12 06:36:54,761 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "*** Error running process: /content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/scripts.py\", line 832, in process\n",
            "        script.process(p, *script_args)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1228, in process\n",
            "        self.controlnet_hack(p)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1213, in controlnet_hack\n",
            "        self.controlnet_main_entry(p)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 890, in controlnet_main_entry\n",
            "        Preprocessor.unload_unused(active_processors={\n",
            "                                                     ^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 893, in <setcomp>\n",
            "        for p in unit.get_actual_preprocessors()\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/internal_controlnet/args.py\", line 274, in get_actual_preprocessors\n",
            "        p = p.get_preprocessor_by_model(self.model)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/preprocessor/ip_adapter_auto.py\", line 16, in get_preprocessor_by_model\n",
            "        module: str = IPAdapterPreset.match_model(model).module\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/ipadapter/presets.py\", line 20, in match_model\n",
            "        model_name in _preset_by_model\n",
            "    AssertionError: None not found in ipadapter presets. Please try manually pick preprocessor.\n",
            "\n",
            "---\n",
            "100% 20/20 [00:04<00:00,  4.53it/s]\n",
            "2025-08-12 06:37:23,700 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:37:24,193 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:37:24,193 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 341\n",
            "2025-08-12 06:37:26,401 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 2.7052505016326904\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:37:30,319 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 64]).\n",
            "100% 20/20 [00:14<00:00,  1.35it/s]\n",
            "2025-08-12 06:38:05,183 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:38:05,677 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:38:05,677 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 341\n",
            "2025-08-12 06:38:10,669 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.489622116088867\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:38:13,614 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 64]).\n",
            "100% 20/20 [00:13<00:00,  1.47it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:38:26,220 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 128, 128]).\n",
            "100% 20/20 [01:37<00:00,  4.85s/it]\n",
            "2025-08-12 06:41:07,408 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 06:41:07,895 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 06:41:07,896 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 06:41:12,823 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.4183876514434814\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:41:15,658 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 63, 64]).\n",
            "100% 20/20 [00:21<00:00,  1.05s/it]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 06:41:35,841 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 126, 128]).\n",
            "100% 20/20 [03:32<00:00, 10.63s/it]\n",
            "100% 20/20 [00:18<00:00,  1.09it/s]\n",
            "100% 20/20 [03:30<00:00, 10.51s/it]\n",
            "100% 20/20 [00:18<00:00,  1.09it/s]\n",
            "100% 20/20 [03:30<00:00, 10.50s/it]\n",
            "100% 20/20 [00:18<00:00,  1.09it/s]\n",
            "100% 20/20 [03:30<00:00, 10.50s/it]\n",
            "2025-08-12 07:03:19,253 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 07:03:19,260 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 07:03:19,260 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 07:03:19,347 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 0.09737396240234375\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:03:22,477 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 63, 64]).\n",
            "100% 20/20 [00:21<00:00,  1.06s/it]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:03:42,568 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 126, 128]).\n",
            "100% 20/20 [03:32<00:00, 10.64s/it]\n",
            "100% 20/20 [00:18<00:00,  1.09it/s]\n",
            "100% 20/20 [03:29<00:00, 10.50s/it]\n",
            "100% 20/20 [00:18<00:00,  1.09it/s]\n",
            "100% 20/20 [03:30<00:00, 10.50s/it]\n",
            "100% 20/20 [00:18<00:00,  1.09it/s]\n",
            "100% 20/20 [03:30<00:00, 10.50s/it]\n",
            "2025-08-12 07:20:17,738 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 07:20:17,748 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 07:20:17,748 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 07:20:17,854 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 0.12012076377868652\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:20:21,788 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 86, 54]).\n",
            "100% 20/20 [00:25<00:00,  1.27s/it]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:20:45,688 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 172, 108]).\n",
            "100% 20/20 [04:06<00:00, 12.32s/it]\n",
            "2025-08-12 07:25:24,422 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 07:25:24,430 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 07:25:24,430 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 07:25:24,519 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 0.10071253776550293\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:25:28,427 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 86, 54]).\n",
            "100% 20/20 [00:24<00:00,  1.23s/it]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:25:51,784 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 172, 108]).\n",
            "100% 20/20 [04:04<00:00, 12.21s/it]\n",
            "2025-08-12 07:37:53,227 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 07:37:53,823 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 07:37:53,823 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 07:37:59,050 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.826928377151489\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:38:02,117 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 64]).\n",
            "100% 20/20 [00:19<00:00,  1.03it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:38:20,973 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 128, 128]).\n",
            "100% 20/20 [03:08<00:00,  9.45s/it]\n",
            "2025-08-12 07:47:15,094 - ControlNet - \u001b[0;32mINFO\u001b[0m - unit_separate = False, style_align = False\n",
            "2025-08-12 07:47:15,660 - ControlNet - \u001b[0;32mINFO\u001b[0m - Using preprocessor: reference_only\n",
            "2025-08-12 07:47:15,660 - ControlNet - \u001b[0;32mINFO\u001b[0m - preprocessor resolution = 512\n",
            "2025-08-12 07:47:20,942 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet Hooked - Time = 5.851724863052368\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:47:23,643 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 64, 64]).\n",
            "100% 20/20 [00:19<00:00,  1.04it/s]\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-08-12 07:47:42,130 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet used torch.float32 VAE to encode torch.Size([1, 4, 128, 128]).\n",
            "100% 20/20 [03:08<00:00,  9.42s/it]\n"
          ]
        }
      ],
      "source": [
        "#────────────────────────────────────────────\n",
        "# ChilloutMix Stable Diffusion WebUI - Google Colab版\n",
        "# リアルな人物画像生成に特化したモデル\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 0) 環境のリセットと準備\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import shutil\n",
        "import requests\n",
        "import json\n",
        "\n",
        "print(\"🎭 ChilloutMix Stable Diffusion WebUI セットアップ開始\")\n",
        "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "print(\"🔄 環境をクリーンアップ中...\")\n",
        "\n",
        "# 既存のディレクトリを削除（クリーンスタート）\n",
        "if os.path.exists('/content/stable-diffusion-webui'):\n",
        "    shutil.rmtree('/content/stable-diffusion-webui')\n",
        "    print(\"✅ 既存のStable Diffusion WebUIディレクトリを削除\")\n",
        "\n",
        "# Google Driveをマウント\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✅ Google Driveマウント完了\")\n",
        "except:\n",
        "    print(\"⚠️ Google Driveは既にマウント済み\")\n",
        "\n",
        "print(\"\\n📝 ChilloutMixについて:\")\n",
        "print(\"• リアルな人物画像生成に特化したモデル\")\n",
        "print(\"• アジア系女性の画像生成で高い品質を発揮\")\n",
        "print(\"• 写実的なポートレート生成が得意\")\n",
        "print(\"• ファイルサイズ: 約4.27GB\")\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 1) 必要なパッケージをインストール\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"\\n📦 必要なパッケージをインストール中...\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq aria2 wget curl git\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 2) Stable Diffusion Web UI をクローン\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"⬇️ Stable Diffusion Web UIをクローン中...\")\n",
        "%cd /content\n",
        "!git clone -q https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 3) PyTorch + CUDA 12.1 をインストール\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"🔥 PyTorch + CUDA 12.1をインストール中...\")\n",
        "%cd /content/stable-diffusion-webui\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 4) 拡張機能をインストール\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"🔌 拡張機能をインストール中...\")\n",
        "%cd /content/stable-diffusion-webui/extensions\n",
        "\n",
        "# ControlNet 拡張をインストール\n",
        "!git clone -q https://github.com/Mikubill/sd-webui-controlnet.git\n",
        "\n",
        "# 顔修復用拡張（代替手段）\n",
        "# GFPGANの代わりに、より軽量なCodeFormerを使用\n",
        "!git clone -q https://github.com/sczhou/CodeFormer.git\n",
        "\n",
        "# 高画質化拡張\n",
        "!git clone -q https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git\n",
        "\n",
        "# タグ補完拡張\n",
        "!git clone -q https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git\n",
        "\n",
        "print(\"✅ 拡張機能のインストール完了\")\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 5) ChilloutMixモデルをダウンロード\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "def download_chilloutmix_model():\n",
        "    \"\"\"ChilloutMixモデルをダウンロード\"\"\"\n",
        "    print(\"🎭 ChilloutMixモデルをダウンロード中...\")\n",
        "\n",
        "    # モデル保存ディレクトリを作成\n",
        "    model_dir = '/content/stable-diffusion-webui/models/Stable-diffusion'\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    # ChilloutMix-Ni (推奨バージョン)\n",
        "    model_urls = [\n",
        "        {\n",
        "            \"name\": \"ChilloutMix-Ni\",\n",
        "            \"filename\": \"chilloutmix_NiPrunedFp32Fix.safetensors\",\n",
        "            \"url\": \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\",\n",
        "            \"size\": \"4.27GB\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for model in model_urls:\n",
        "        print(f\"⬇️ {model['name']} ({model['size']}) をダウンロード中...\")\n",
        "        output_path = f\"{model_dir}/{model['filename']}\"\n",
        "\n",
        "        # aria2cでダウンロード\n",
        "        result = subprocess.run([\n",
        "            'aria2c',\n",
        "            '-c', '-x16', '-s16',\n",
        "            '--check-certificate=false',\n",
        "            '--summary-interval=10',\n",
        "            '--max-tries=5',\n",
        "            '--retry-wait=3',\n",
        "            model['url'],\n",
        "            '-d', model_dir,\n",
        "            '-o', model['filename']\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode != 0:\n",
        "            print(f\"❌ {model['name']}のダウンロードに失敗\")\n",
        "            print(\"🔄 代替URLを試行中...\")\n",
        "\n",
        "            # 代替URL\n",
        "            alt_urls = [\n",
        "                f\"https://huggingface.co/MarWinWinWinWin/ChillOutMix/resolve/main/{model['filename']}\",\n",
        "                f\"https://huggingface.co/balapapapa/chilloutmix/resolve/main/{model['filename']}\",\n",
        "                f\"https://huggingface.co/samle/sd-webui-models/resolve/main/{model['filename']}\"\n",
        "            ]\n",
        "\n",
        "            success = False\n",
        "            for alt_url in alt_urls:\n",
        "                print(f\"🔄 代替URL試行: {alt_url.split('/')[-3]}\")\n",
        "                result = subprocess.run([\n",
        "                    'aria2c',\n",
        "                    '-c', '-x8', '-s8',\n",
        "                    '--check-certificate=false',\n",
        "                    '--max-tries=3',\n",
        "                    alt_url,\n",
        "                    '-d', model_dir,\n",
        "                    '-o', model['filename']\n",
        "                ], capture_output=True, text=True)\n",
        "\n",
        "                if result.returncode == 0 and os.path.exists(output_path):\n",
        "                    success = True\n",
        "                    break\n",
        "\n",
        "            if not success:\n",
        "                print(\"❌ すべての代替URLでダウンロードに失敗\")\n",
        "                print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "                print(\"🚨 手動ダウンロード手順:\")\n",
        "                print(\"1. https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix\")\n",
        "                print(\"2. chilloutmix_NiPrunedFp32Fix.safetensors をダウンロード\")\n",
        "                print(\"3. Google Colabにアップロードして以下に配置:\")\n",
        "                print(f\"   {model_dir}/{model['filename']}\")\n",
        "                print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "                continue\n",
        "\n",
        "        # ファイル検証\n",
        "        if os.path.exists(output_path):\n",
        "            file_size = os.path.getsize(output_path)\n",
        "            if file_size > 1000000000:  # 1GB以上\n",
        "                print(f\"✅ {model['name']} ダウンロード完了 ({file_size / (1024*1024*1024):.2f} GB)\")\n",
        "            else:\n",
        "                print(f\"⚠️ {model['name']} ファイルサイズが小さすぎます ({file_size} bytes)\")\n",
        "        else:\n",
        "            print(f\"❌ {model['name']} ファイルが見つかりません\")\n",
        "\n",
        "# ChilloutMixモデルのダウンロード実行\n",
        "download_chilloutmix_model()\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 6) VAE (変分オートエンコーダー) をダウンロード\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"\\n🎨 VAEモデルをダウンロード中...\")\n",
        "\n",
        "vae_dir = '/content/stable-diffusion-webui/models/VAE'\n",
        "os.makedirs(vae_dir, exist_ok=True)\n",
        "\n",
        "# 高品質なVAEモデル\n",
        "vae_models = [\n",
        "    {\n",
        "        \"name\": \"vae-ft-mse-840000-ema-pruned.safetensors\",\n",
        "        \"url\": \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for vae in vae_models:\n",
        "    print(f\"⬇️ {vae['name']} をダウンロード中...\")\n",
        "    result = subprocess.run([\n",
        "        'aria2c', '-c', '-x8', '-s8',\n",
        "        vae['url'],\n",
        "        '-d', vae_dir\n",
        "    ], capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(f\"✅ {vae['name']} ダウンロード完了\")\n",
        "    else:\n",
        "        print(f\"⚠️ {vae['name']} ダウンロード失敗\")\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 7) ControlNet モデルをダウンロード\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"\\n🎮 ControlNet モデルをダウンロード中...\")\n",
        "\n",
        "controlnet_dir = '/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models'\n",
        "os.makedirs(controlnet_dir, exist_ok=True)\n",
        "\n",
        "# ControlNet モデル\n",
        "controlnet_models = [\n",
        "    {\n",
        "        \"name\": \"control_v11p_sd15_openpose.pth\",\n",
        "        \"url\": \"https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"control_v11f1p_sd15_depth.pth\",\n",
        "        \"url\": \"https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"control_v11p_sd15_canny.pth\",\n",
        "        \"url\": \"https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for model in controlnet_models:\n",
        "    print(f\"⬇️ {model['name']} をダウンロード中...\")\n",
        "    result = subprocess.run([\n",
        "        'aria2c', '-c', '-x4', '-s4',\n",
        "        model['url'],\n",
        "        '-d', controlnet_dir\n",
        "    ], capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(f\"✅ {model['name']} ダウンロード完了\")\n",
        "    else:\n",
        "        print(f\"⚠️ {model['name']} ダウンロード失敗（スキップ）\")\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 8) 必要ライブラリをインストール\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"\\n📚 追加ライブラリをインストール中...\")\n",
        "\n",
        "# xFormersの問題を回避するため、互換性のあるバージョンをインストール\n",
        "print(\"🔧 xFormersの互換性問題を修正中...\")\n",
        "!pip uninstall -y xformers\n",
        "!pip install -q xformers==0.0.20 --no-deps\n",
        "\n",
        "# 必要なライブラリをインストール\n",
        "!pip install -q open_clip_torch transformers timm\n",
        "!pip install -q opencv-python\n",
        "!pip install -q basicsr facexlib realesrgan gfpgan  # 顔修復用依存関係\n",
        "\n",
        "print(\"✅ xFormers修正完了\")\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 9) 設定ファイルを作成\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"⚙️ ChilloutMix用設定ファイルを作成中...\")\n",
        "\n",
        "# config.jsonを作成（ChilloutMix最適化設定）\n",
        "config_content = \"\"\"{\n",
        "    \"samples_save\": true,\n",
        "    \"samples_format\": \"png\",\n",
        "    \"samples_filename_pattern\": \"\",\n",
        "    \"save_images_add_number\": true,\n",
        "    \"grid_save\": true,\n",
        "    \"grid_format\": \"png\",\n",
        "    \"grid_extended_filename\": false,\n",
        "    \"grid_only_if_multiple\": true,\n",
        "    \"grid_prevent_empty_spots\": false,\n",
        "    \"n_rows\": -1,\n",
        "    \"enable_pnginfo\": true,\n",
        "    \"save_txt\": false,\n",
        "    \"save_images_before_face_restoration\": true,\n",
        "    \"save_images_before_highres_fix\": false,\n",
        "    \"save_images_before_color_correction\": false,\n",
        "    \"jpeg_quality\": 95,\n",
        "    \"webp_lossless\": false,\n",
        "    \"export_for_4chan\": true,\n",
        "    \"img_downscale_threshold\": 4.0,\n",
        "    \"target_side_length\": 4000,\n",
        "    \"img_max_size_mp\": 200,\n",
        "    \"use_original_name_batch\": true,\n",
        "    \"use_upscaler_name_as_suffix\": false,\n",
        "    \"save_selected_only\": true,\n",
        "    \"do_not_add_watermark\": false,\n",
        "    \"temp_dir\": \"\",\n",
        "    \"clean_temp_dir_at_start\": false,\n",
        "    \"CLIP_stop_at_last_layers\": 2,\n",
        "    \"upscaling_max_images_in_cache\": 5,\n",
        "    \"face_restoration_model\": \"GFPGAN\",\n",
        "    \"code_former_weight\": 0.5,\n",
        "    \"face_restoration_unload\": false\n",
        "}\"\"\"\n",
        "\n",
        "with open('/content/stable-diffusion-webui/config.json', 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "# styles.csvを作成（ChilloutMix用プリセット）\n",
        "styles_content = \"\"\"name,prompt,negative_prompt\n",
        "\"ChilloutMix Portrait\",\"(best quality, masterpiece:1.2), (realistic, photo-realistic:1.37), ultra detailed, 1 girl, cute, solo, beautiful detailed sky, detailed cafe, night, sitting, dating, (nose blush), (smile:1.15), (closed mouth) small breasts, beautiful detailed eyes, (collared shirt:1.1), bowtie, pleated skirt, (short hair:1.2), floating hair NovaFrogStyle\",\"(worst quality, low quality:1.4), (realistic, lip, nose, tooth, rouge, lipstick, eyeshadow:1.0), (dusty sunbeams:1.0),, (abs, muscular, rib:1.0), (depth of field, bokeh, blurry, film grain, chromatic aberration, lens flare:1.0), (1boy, abs, muscular, rib:1.0), greyscale, monochrome, dusty sunbeams, trembling, motion lines, motion blur, emphasis lines, text, title, logo, signature\"\n",
        "\"ChilloutMix Realistic\",\"(8k, RAW photo, best quality, masterpiece:1.2), (realistic, photo-realistic:1.37), professional lighting, photon mapping, radiosity, physically-based rendering, cinematic lighting, intricate, High Detail, Sharp focus, dramatic, photorealistic painting\",\"(worst quality, low quality:1.4), (realistic, lip, nose, tooth, rouge, lipstick, eyeshadow:1.0), (dusty sunbeams:1.0), (abs, muscular, rib:1.0), (depth of field, bokeh, blurry, film grain, chromatic aberration, lens flare:1.0), text, title, logo, signature\"\n",
        "\"ChilloutMix Asian Beauty\",\"(masterpiece, best quality), (realistic:1.3), finely detailed beautiful eyes and detailed face, masterpiece, best quality, (extremely detailed CG unity 8k wallpaper), most beautiful artwork in the world, professional majestic oil painting, intricate, High Detail, Sharp focus, dramatic, photorealistic, (asian girl), beautiful face, high detail eyes, elegant\",\"(worst quality, low quality:1.4), multiple people, logo, text, badhandv4, (bad anatomy), (inaccurate limb), bad composition, inaccurate eyes, extra digit, fewer digits, (extra arms)\"\n",
        "\"ChilloutMix Studio\",\"studio lighting, professional photography, (masterpiece, best quality), (realistic:1.3), finely detailed beautiful eyes and detailed face, intricate High Detail, Sharp focus, dramatic, (upper body:1.2), looking at viewer\",\"(worst quality, low quality:1.4), (depth of field, bokeh, blurry:1.4), (greyscale, monochrome:1.0), text, title, logo, signature\"\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/stable-diffusion-webui/styles.csv', 'w') as f:\n",
        "    f.write(styles_content)\n",
        "\n",
        "print(\"✅ 設定ファイル作成完了\")\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 10) 起動前の最終チェック\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎭 ChilloutMix セットアップ完了サマリー:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# モデルファイルの確認\n",
        "model_dir = \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith(('.safetensors', '.ckpt'))]\n",
        "\n",
        "print(f\"📁 インストールされたモデル:\")\n",
        "for model_file in model_files:\n",
        "    file_path = os.path.join(model_dir, model_file)\n",
        "    file_size = os.path.getsize(file_path) / (1024*1024*1024)\n",
        "    print(f\"   ✅ {model_file} ({file_size:.2f} GB)\")\n",
        "\n",
        "print(f\"\\n🔌 インストールされた拡張機能:\")\n",
        "ext_dir = \"/content/stable-diffusion-webui/extensions\"\n",
        "extensions = [d for d in os.listdir(ext_dir) if os.path.isdir(os.path.join(ext_dir, d))]\n",
        "for ext in extensions:\n",
        "    print(f\"   ✅ {ext}\")\n",
        "\n",
        "print(f\"\\n🎯 ChilloutMix 推奨設定:\")\n",
        "print(\"   📸 モデル: ChilloutMix-Ni\")\n",
        "print(\"   📐 解像度: 512x768 または 512x512\")\n",
        "print(\"   🎛️ CFG Scale: 7-12\")\n",
        "print(\"   🔄 Steps: 20-30\")\n",
        "print(\"   🎲 Sampler: DPM++ 2M Karras または Euler a\")\n",
        "print(\"   🎨 CLIP Skip: 2\")\n",
        "\n",
        "print(f\"\\n✨ ChilloutMix 特徴:\")\n",
        "print(\"   • リアルな人物画像生成に特化\")\n",
        "print(\"   • アジア系女性のポートレートで高品質\")\n",
        "print(\"   • 写実的な肌質・髪質表現\")\n",
        "print(\"   • スタジオ撮影風の画像生成\")\n",
        "\n",
        "print(f\"\\n💡 推奨プロンプト例:\")\n",
        "print('   • \"1girl, portrait, realistic, beautiful detailed eyes\"')\n",
        "print('   • \"professional photography, studio lighting, asian girl\"')\n",
        "print('   • \"masterpiece, best quality, photorealistic, upper body\"')\n",
        "\n",
        "print(f\"\\n⚠️ Google Colab使用時の注意事項:\")\n",
        "print(\"   • メモリ不足エラーが出た場合は解像度を512x512に下げる\")\n",
        "print(\"   • 長時間使用すると接続が切れる場合がある\")\n",
        "print(\"   • 高品質画像は時間がかかる場合がある\")\n",
        "\n",
        "print(f\"\\n🔧 エラー対策済み:\")\n",
        "print(\"   • xFormersバージョン不整合を修正\")\n",
        "print(\"   • GFPGAN依存関係エラーを解決\")\n",
        "print(\"   • メモリ効率を改善（--lowvram使用）\")\n",
        "print(\"   • CUDA最適化設定を追加\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "#────────────────────────────────────────────\n",
        "# 11) Web UI を起動\n",
        "#────────────────────────────────────────────\n",
        "\n",
        "print(\"🚀 ChilloutMix Web UIを起動中...\")\n",
        "print(\"⏳ 初回起動には数分かかる場合があります...\")\n",
        "print(\"\\n📱 起動完了後、共有URLが表示されます\")\n",
        "\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "# 環境変数を設定してxFormersの問題を完全に回避（ナレッジと同じ設定）\n",
        "import os\n",
        "os.environ['XFORMERS_FORCE_DISABLE_TRITON'] = '1'\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# Web UIを起動（WAI-NSFWと同じ設定、xFormers問題回避版）\n",
        "!python launch.py \\\n",
        "    --share \\\n",
        "    --skip-torch-cuda-test \\\n",
        "    --disable-console-progressbars \\\n",
        "    --opt-sdp-attention \\\n",
        "    --enable-insecure-extension-access \\\n",
        "    --lora-dir \"/content/stable-diffusion-webui/models/Lora\" \\\n",
        "    --no-half \\\n",
        "    --precision full \\\n",
        "    --medvram \\\n",
        "    --no-half-vae \\\n",
        "    --api \\\n",
        "    --cors-allow-origins=\"*\"\n",
        "\n",
        "print(\"\\n🎉 ChilloutMix Web UI起動完了!\")\n",
        "print(\"🎭 リアルな人物画像生成をお楽しみください！\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO28yxtwBe1r/ValfKLpeVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}