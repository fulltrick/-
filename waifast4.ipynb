{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fulltrick/-/blob/main/waifast4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "#  Stable Diffusion WebUI (A1111) を Python 3.10 で起動する版\n",
    "#  - Colab カーネルは 3.11/3.12 でもOK（実行系だけ 3.10）\n",
    "#  - xFormers 未使用（--opt-sdp-attention でSDPA）\n",
    "#  - ControlNet (SDXL) / Civitai 取得ロジックを踏襲\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "import importlib.util\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "IPY_SPEC = importlib.util.find_spec(\"IPython\")\n",
    "DISPLAY_SPEC = importlib.util.find_spec(\"IPython.display\") if IPY_SPEC else None\n",
    "if DISPLAY_SPEC is not None:\n",
    "    from IPython.display import Audio, display  # type: ignore\n",
    "else:\n",
    "    class _DummyAudio:\n",
    "        def __init__(self, *, data, rate, autoplay):\n",
    "            self.data = data\n",
    "            self.rate = rate\n",
    "            self.autoplay = autoplay\n",
    "\n",
    "        def __repr__(self):\n",
    "            duration = len(self.data) / self.rate if self.rate else 0\n",
    "            return f\"Audio(dry-run, {duration:.2f}s, autoplay={self.autoplay})\"\n",
    "\n",
    "    def display(obj):  # noqa: D401 - simple console stub\n",
    "        print(f\"🔈 {obj}\")\n",
    "\n",
    "    def Audio(*, data, rate, autoplay):  # noqa: N802 - mimic IPython API\n",
    "        return _DummyAudio(data=data, rate=rate, autoplay=autoplay)\n",
    "\n",
    "NP_SPEC = importlib.util.find_spec(\"numpy\")\n",
    "if NP_SPEC is not None:\n",
    "    import numpy as np  # noqa: WPS433 - runtime optional import\n",
    "else:\n",
    "    np = None\n",
    "\n",
    "\n",
    "def _is_truthy(value: str | None) -> bool:\n",
    "    if value is None:\n",
    "        return False\n",
    "    return value.strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n",
    "\n",
    "\n",
    "DRY_RUN = _is_truthy(os.environ.get(\"WAIFAST4_DRY_RUN\"))\n",
    "\n",
    "if DRY_RUN:\n",
    "    Path(\"/content/drive/MyDrive\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(\"/content/stable-diffusion-webui\").parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "MICROMAMBA = (\n",
    "    Path(\"/usr/local/bin/micromamba\")\n",
    "    if not DRY_RUN\n",
    "    else Path(\"/tmp/waifast4/micromamba\")\n",
    ")\n",
    "\n",
    "if DRY_RUN:\n",
    "    MICROMAMBA.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "GOOGLE_SPEC = importlib.util.find_spec(\"google\")\n",
    "colab_spec = importlib.util.find_spec(\"google.colab\") if GOOGLE_SPEC else None\n",
    "\n",
    "if colab_spec is None:\n",
    "    class _DummyDrive:\n",
    "        def mount(self, *_args, **_kwargs):\n",
    "            if DRY_RUN:\n",
    "                print(\"⚠️ (dry-run) Google Drive マウントをスキップします\")\n",
    "                return\n",
    "            raise ModuleNotFoundError(\n",
    "                \"google.colab.drive は Colab 以外では使用できません\"\n",
    "            )\n",
    "\n",
    "\n",
    "    class _DummyUserData(dict):\n",
    "        def get(self, key, default=None):  # noqa: D401\n",
    "            if DRY_RUN:\n",
    "                return os.environ.get(key, default)\n",
    "            raise ModuleNotFoundError(\n",
    "                \"google.colab.userdata は Colab 以外では使用できません\"\n",
    "            )\n",
    "\n",
    "\n",
    "    drive = _DummyDrive()\n",
    "    userdata = _DummyUserData()\n",
    "else:\n",
    "    from google.colab import drive, userdata\n",
    "\n",
    "def run(cmd, *, cwd=None, check=True, **kwargs):\n",
    "    if isinstance(cmd, (list, tuple)):\n",
    "        printable = ' '.join(str(c) for c in cmd)\n",
    "    else:\n",
    "        printable = cmd\n",
    "    print(f\"$ {printable}\")\n",
    "    if DRY_RUN:\n",
    "        print(\"   ↪︎ dry-run: 実行をスキップしました\")\n",
    "        stdout = '' if kwargs.get('capture_output') else None\n",
    "        stderr = '' if kwargs.get('capture_output') else None\n",
    "        return subprocess.CompletedProcess(cmd, 0, stdout=stdout, stderr=stderr)\n",
    "    return subprocess.run(cmd, cwd=cwd, check=check, **kwargs)\n",
    "\n",
    "\n",
    "def ensure_micromamba():\n",
    "    if MICROMAMBA.exists():\n",
    "        return\n",
    "    if DRY_RUN:\n",
    "        MICROMAMBA.write_text(\"#!/bin/sh\\nexit 0\\n\")\n",
    "        MICROMAMBA.chmod(0o755)\n",
    "        print(\"⚠️ (dry-run) micromamba をダミー作成しました\")\n",
    "        return\n",
    "    archive = Path('/tmp/micromamba.tar.bz2')\n",
    "    run(['wget', '-qO', str(archive), 'https://micromamba.snakepit.net/api/micromamba/linux-64/latest'])\n",
    "    run(['tar', '-xjf', str(archive), '-C', '/usr/local/bin', '--strip-components=1', 'bin/micromamba'])\n",
    "\n",
    "\n",
    "def ensure_directories():\n",
    "    drive_base_data_path = Path('/content/drive/MyDrive/sd_colab_data')\n",
    "    drive_models_path = drive_base_data_path / 'models/Stable-diffusion'\n",
    "    drive_controlnet_path = drive_base_data_path / 'models/ControlNet'\n",
    "    drive_vae_path = drive_base_data_path / 'models/VAE-approx'\n",
    "    for p in (drive_models_path, drive_controlnet_path, drive_vae_path):\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "    return drive_models_path, drive_controlnet_path, drive_vae_path\n",
    "\n",
    "\n",
    "def download_civitai_model(token: str, drive_models_path: Path):\n",
    "    print(\"\\n🔑 Civitai API トークンを取得（Colab 左の🔑から事前登録）...\")\n",
    "    if DRY_RUN:\n",
    "        dummy_name = 'dryrun-model.safetensors'\n",
    "        output_drive = drive_models_path / dummy_name\n",
    "        output_local_dir = Path('/content/stable-diffusion-webui/models/Stable-diffusion')\n",
    "        output_local_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_drive.parent.mkdir(parents=True, exist_ok=True)\n",
    "        output_drive.write_bytes(b'')\n",
    "        shutil.copy(output_drive, output_local_dir / dummy_name)\n",
    "        print('✅ (dry-run) Civitai モデル準備をスキップしました')\n",
    "        return\n",
    "\n",
    "    def get_latest_model_version_id(token: str):\n",
    "        print(\"🔍 WAI-NSFW-illustrious-SDXL の最新バージョンIDを取得中...\")\n",
    "        model_id = '827184'\n",
    "        api_url = f\"https://civitai.com/api/v1/models/{model_id}?token={token}\"\n",
    "        r = run(['curl', '-s', api_url], capture_output=True, text=True)\n",
    "        if r.returncode != 0 or not r.stdout:\n",
    "            print(\"⚠️ API呼び出しエラー、既知IDへフォールバックします\")\n",
    "            return None\n",
    "        try:\n",
    "            data = json.loads(r.stdout)\n",
    "            mv = data.get('modelVersions') or []\n",
    "            if mv:\n",
    "                vid = str(mv[0]['id'])\n",
    "                print(f\"✅ 最新バージョンIDを取得: {vid}\")\n",
    "                return vid\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ APIレスポンスを解析できませんでした\")\n",
    "        return None\n",
    "\n",
    "    def download_model(token: str, version_id: str):\n",
    "        api = f\"https://civitai.com/api/v1/model-versions/{version_id}?token={token}\"\n",
    "        r = run(['curl', '-s', api], capture_output=True, text=True)\n",
    "        if r.returncode != 0 or not r.stdout:\n",
    "            raise SystemExit('❌ モデル情報の取得に失敗しました')\n",
    "        data = json.loads(r.stdout)\n",
    "        files = data.get('files') or []\n",
    "        chosen = next((f for f in files if f.get('type') == 'Model'), None)\n",
    "        if not chosen:\n",
    "            raise SystemExit('❌ モデルファイルが見つかりません')\n",
    "        download_url = chosen['downloadUrl'] + f\"?token={token}\"\n",
    "        output_filename = chosen['name']\n",
    "        output_drive = drive_models_path / output_filename\n",
    "        output_local = Path('/content/stable-diffusion-webui/models/Stable-diffusion') / output_filename\n",
    "        print(f\"⬇️ {output_filename} をダウンロードします...\")\n",
    "        if DRY_RUN:\n",
    "            output_drive.parent.mkdir(parents=True, exist_ok=True)\n",
    "            output_local.parent.mkdir(parents=True, exist_ok=True)\n",
    "            output_drive.write_bytes(b'')\n",
    "            shutil.copy(output_drive, output_local)\n",
    "            print('✅ (dry-run) モデルのダウンロードをスキップしました')\n",
    "            return\n",
    "        aria_args = ['aria2c', '-c', '-x16', '-s16', '--check-certificate=false',\n",
    "                     download_url, '-d', str(drive_models_path), '-o', output_filename]\n",
    "        result = run(aria_args)\n",
    "        if result.returncode == 0 and output_drive.exists():\n",
    "            shutil.copy(output_drive, output_local)\n",
    "            print('✅ Civitai からモデルをダウンロードしました')\n",
    "        else:\n",
    "            raise SystemExit('❌ モデルのダウンロードに失敗しました')\n",
    "\n",
    "    vid = get_latest_model_version_id(token)\n",
    "    if vid:\n",
    "        download_model(token, vid)\n",
    "        return\n",
    "    for fallback in ['1410435', '1396035', '1378467', '1360950']:\n",
    "        try:\n",
    "            download_model(token, fallback)\n",
    "            return\n",
    "        except SystemExit:\n",
    "            continue\n",
    "    raise SystemExit('❌ すべてのモデルダウンロードに失敗しました')\n",
    "\n",
    "\n",
    "def prepare_controlnet(drive_controlnet_path: Path):\n",
    "    controlnet_dir_local = Path('/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models')\n",
    "    controlnet_dir_local.mkdir(parents=True, exist_ok=True)\n",
    "    if DRY_RUN:\n",
    "        for name in ['OpenPoseXL2.safetensors', 'diffusers_xl_canny_full.safetensors']:\n",
    "            drive_file = drive_controlnet_path / name\n",
    "            drive_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            drive_file.write_bytes(b'')\n",
    "            (controlnet_dir_local / name).write_bytes(b'')\n",
    "        print('✅ (dry-run) ControlNet モデル準備をスキップしました')\n",
    "        return\n",
    "    models = [\n",
    "        ('OpenPoseXL2.safetensors',\n",
    "         'https://huggingface.co/thibaud/controlnet-openpose-sdxl-1.0/resolve/main/OpenPoseXL2.safetensors'),\n",
    "        ('diffusers_xl_canny_full.safetensors',\n",
    "         'https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_canny_full.safetensors')\n",
    "    ]\n",
    "    for name, url in models:\n",
    "        p_drive = drive_controlnet_path / name\n",
    "        p_local = controlnet_dir_local / name\n",
    "        if p_drive.exists() and p_drive.stat().st_size > 1_000_000:\n",
    "            shutil.copy(p_drive, p_local)\n",
    "            continue\n",
    "        run(['aria2c', '-c', '-x8', '-s8', url, '-d', str(drive_controlnet_path), '-o', name])\n",
    "        if p_drive.exists():\n",
    "            shutil.copy(p_drive, p_local)\n",
    "    print('✅ ControlNet モデル準備完了')\n",
    "\n",
    "\n",
    "def write_config():\n",
    "    config = \"\"\"{\n",
    "  \"samples_save\": true,\n",
    "  \"samples_format\": \"png\",\n",
    "  \"grid_save\": true,\n",
    "  \"grid_format\": \"png\",\n",
    "  \"enable_pnginfo\": true,\n",
    "  \"save_selected_only\": true,\n",
    "  \"jpeg_quality\": 80,\n",
    "  \"export_for_4chan\": true,\n",
    "  \"img_downscale_threshold\": 4.0,\n",
    "  \"target_side_length\": 4000,\n",
    "  \"img_max_size_mp\": 200\n",
    "}\"\"\"\n",
    "    cfg_path = Path('/content/stable-diffusion-webui/config.json')\n",
    "    cfg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cfg_path.write_text(config)\n",
    "\n",
    "\n",
    "def play_notification():\n",
    "    if np is None:\n",
    "        print('🔔 (dry-run) numpy が無いためサウンド再生をスキップしました')\n",
    "        return\n",
    "    sr = 22050\n",
    "    t = np.linspace(0, 0.75, int(sr * 0.75), endpoint=False)\n",
    "    tone = 0.3 * np.sin(2 * np.pi * 880 * t) * np.exp(-3 * t)\n",
    "    display(Audio(data=tone, rate=sr, autoplay=True))\n",
    "\n",
    "\n",
    "\n",
    "def start_gradio_live_monitor(url: str, proc: subprocess.Popen) -> None:\n",
    "    url = (url or '').strip()\n",
    "    if not url:\n",
    "        print('⚠️ Gradio Live のURLを特定できませんでしたが通知を再生します')\n",
    "        play_notification()\n",
    "        return\n",
    "    if DRY_RUN:\n",
    "        print(f'🔔 (dry-run) Gradio Live URL 検知: {url}')\n",
    "        play_notification()\n",
    "        return\n",
    "\n",
    "    def _worker() -> None:\n",
    "        print(f'⏳ Gradio Live URL の疎通確認を開始します: {url}')\n",
    "        while True:\n",
    "            if proc.poll() is not None:\n",
    "                print('⚠️ WebUI プロセスが終了したため通知待機を中断します')\n",
    "                return\n",
    "            try:\n",
    "                with urllib.request.urlopen(url, timeout=10) as response:\n",
    "                    status = getattr(response, 'status', None)\n",
    "                    if status is None:\n",
    "                        status = response.getcode()\n",
    "                    if status is None:\n",
    "                        status = 200\n",
    "                    if 200 <= status < 400:\n",
    "                        print(f'✅ Gradio Live にアクセスできました (status={status})')\n",
    "                        play_notification()\n",
    "                        return\n",
    "                    print(f'   ↪︎ 応答を受信しました (status={status}) - 再確認します')\n",
    "            except urllib.error.HTTPError as exc:\n",
    "                print(f'   ↪︎ アクセス待機中... (HTTP {exc.code})')\n",
    "            except urllib.error.URLError as exc:\n",
    "                print(f'   ↪︎ アクセス待機中... ({exc.reason})')\n",
    "            except Exception as exc:\n",
    "                print(f'   ↪︎ アクセス待機中... ({exc})')\n",
    "            time.sleep(3)\n",
    "\n",
    "    threading.Thread(target=_worker, name='gradio-live-monitor', daemon=True).start()\n",
    "\n",
    "\n",
    "_active_processes = []\n",
    "\n",
    "\n",
    "def launch_webui():\n",
    "    env = os.environ.copy()\n",
    "    env['TORCH_COMMAND'] = 'pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121'\n",
    "    cmd = [\n",
    "        str(MICROMAMBA), 'run', '-n', 'py310', 'python', 'launch.py',\n",
    "        '--share', '--listen', '--disable-console-progressbars', '--opt-sdp-attention',\n",
    "        '--enable-insecure-extension-access', '--lora-dir', '/content/stable-diffusion-webui/models/Lora',\n",
    "        '--medvram-sdxl', '--no-half-vae', '--api', '--cors-allow-origins=*'\n",
    "    ]\n",
    "    print('\\n🚀 WebUIを起動します (Python 3.10環境)')\n",
    "    if DRY_RUN:\n",
    "        print('   ↪︎ (dry-run) WebUI 起動をスキップしました')\n",
    "        return\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)\n",
    "    _active_processes.append(proc)\n",
    "\n",
    "    stop_event = threading.Event()\n",
    "\n",
    "    def monitor():\n",
    "        notified = False\n",
    "        stream = proc.stdout\n",
    "        if stream is None:\n",
    "            proc.wait()\n",
    "            if proc.returncode not in (0, None) and not stop_event.is_set():\n",
    "                print(f\"\\n❌ WebUI が終了しました (returncode={proc.returncode})\")\n",
    "            return\n",
    "        try:\n",
    "            while not stop_event.is_set():\n",
    "                line = stream.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                sys.stdout.write(line)\n",
    "                if not notified and 'Running on public URL:' in line:\n",
    "                    public_url = line.split('Running on public URL:', 1)[1].strip()\n",
    "                    start_gradio_live_monitor(public_url, proc)\n",
    "                    notified = True\n",
    "        finally:\n",
    "            proc.wait()\n",
    "            if proc.returncode not in (0, None) and not stop_event.is_set():\n",
    "                print(f\"\\n❌ WebUI が終了しました (returncode={proc.returncode})\")\n",
    "\n",
    "    monitor_thread = threading.Thread(target=monitor, name='waifast4-webui-monitor', daemon=True)\n",
    "    monitor_thread.start()\n",
    "\n",
    "    try:\n",
    "        while monitor_thread.is_alive():\n",
    "            monitor_thread.join(timeout=0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⏹️ WebUI 停止要求を受信しました。プロセスを終了します...\")\n",
    "        stop_event.set()\n",
    "        if proc.poll() is None:\n",
    "            proc.terminate()\n",
    "            try:\n",
    "                proc.wait(timeout=10)\n",
    "            except subprocess.TimeoutExpired:\n",
    "                proc.kill()\n",
    "                proc.wait()\n",
    "        else:\n",
    "            proc.wait()\n",
    "        return\n",
    "    finally:\n",
    "        stop_event.set()\n",
    "        monitor_thread.join(timeout=5)\n",
    "        if proc.stdout is not None:\n",
    "            proc.stdout.close()\n",
    "        if proc in _active_processes:\n",
    "            _active_processes.remove(proc)\n",
    "\n",
    "\n",
    "print('🧪 Notebook kernel Python (参考):')\n",
    "run(['python', '-V'])\n",
    "\n",
    "print('\\n📦 micromamba をセットアップして py310 環境を作成...')\n",
    "ensure_micromamba()\n",
    "run([str(MICROMAMBA), 'create', '-y', '-n', 'py310', '-c', 'conda-forge', 'python=3.10.13', 'pip', 'git', 'aria2', 'curl'])\n",
    "\n",
    "print('\\n🧪 Runtime (py310) バージョン確認：')\n",
    "run([str(MICROMAMBA), 'run', '-n', 'py310', 'python', '-V'])\n",
    "\n",
    "print('\\n🔧 apt / Google Drive 準備...')\n",
    "run(['apt-get', 'update', '-qq'])\n",
    "run(['apt-get', 'install', '-y', '-qq', 'aria2', 'wget', 'curl'])\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print('✅ Google Drive をマウントしました')\n",
    "except Exception as e:\n",
    "    print(f'⚠️ Drive マウント失敗または既にマウント済み: {e}')\n",
    "\n",
    "drive_models_path, drive_controlnet_path, drive_vae_path = ensure_directories()\n",
    "\n",
    "webui_path = Path('/content/stable-diffusion-webui')\n",
    "if webui_path.exists():\n",
    "    shutil.rmtree(webui_path)\n",
    "    print(f'🧹 既存のWebUIを削除: {webui_path}')\n",
    "\n",
    "print('\\n⬇️ Stable Diffusion WebUI をクローン...')\n",
    "os.chdir('/content')\n",
    "run(['git', 'clone', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui.git'])\n",
    "if DRY_RUN:\n",
    "    webui_path.mkdir(parents=True, exist_ok=True)\n",
    "    (webui_path / 'extensions').mkdir(parents=True, exist_ok=True)\n",
    "    (webui_path / 'models/Stable-diffusion').mkdir(parents=True, exist_ok=True)\n",
    "    (webui_path / 'models/Lora').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('\\n🔥 PyTorch (cu121) を py310 環境へインストール...')\n",
    "run([str(MICROMAMBA), 'run', '-n', 'py310', 'python', '-m', 'pip', 'install', '--upgrade', 'pip'])\n",
    "run([str(MICROMAMBA), 'run', '-n', 'py310', 'pip', 'install', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch', 'torchvision', 'torchaudio'])\n",
    "\n",
    "print('\\n📚 追加ライブラリ（py310 環境）をインストール...')\n",
    "run([str(MICROMAMBA), 'run', '-n', 'py310', 'pip', 'install', 'open_clip_torch', 'transformers', 'timm', 'requests'])\n",
    "\n",
    "print('\\n🔌 拡張機能インストール...')\n",
    "os.chdir('/content/stable-diffusion-webui/extensions')\n",
    "run(['git', 'clone', 'https://github.com/Mikubill/sd-webui-controlnet.git'])\n",
    "run(['git', 'clone', 'https://github.com/butaixianran/Stable-Diffusion-Webui-Civitai-Helper.git'])\n",
    "if DRY_RUN:\n",
    "    Path('sd-webui-controlnet').mkdir(parents=True, exist_ok=True)\n",
    "    Path('Stable-Diffusion-Webui-Civitai-Helper').mkdir(parents=True, exist_ok=True)\n",
    "print('✅ 拡張インストール完了')\n",
    "\n",
    "print('\\n🔑 CIVITAI_API_TOKEN を検出中...')\n",
    "try:\n",
    "    civitai_token = (userdata.get('CIVITAI_API_TOKEN') or '').strip()\n",
    "    if not civitai_token and DRY_RUN:\n",
    "        civitai_token = 'dry-run-token'\n",
    "    if not civitai_token:\n",
    "        raise ValueError('CIVITAI_API_TOKEN が未設定')\n",
    "    os.environ['CIVITAI_API_TOKEN'] = civitai_token\n",
    "    print('✅ CIVITAI_API_TOKEN を検出')\n",
    "except Exception as e:\n",
    "    print('❌ Civitai APIトークンが見つかりません')\n",
    "    print('   → サイドバーの 🔑 Secrets で `CIVITAI_API_TOKEN` を設定して再実行してください。')\n",
    "    raise\n",
    "\n",
    "os.chdir('/content/stable-diffusion-webui')\n",
    "download_civitai_model(civitai_token, drive_models_path)\n",
    "prepare_controlnet(drive_controlnet_path)\n",
    "write_config()\n",
    "\n",
    "os.environ.pop('MPLBACKEND', None)\n",
    "\n",
    "print('\\n🔎 insightface (追加) をインストール...')\n",
    "run([str(MICROMAMBA), 'run', '-n', 'py310', 'pip', 'install', 'insightface'])\n",
    "\n",
    "launch_webui()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "runtime_attributes": {
    "runtime_version": "2025.07"
   },
   "provenance": [],
   "authorship_tag": "ABX9TyMc1C1WrF2UCfu+YclJaRMa",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}